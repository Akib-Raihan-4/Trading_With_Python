{"cells":[{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import yfinance as yf\n","import pandas as pd\n","\n","def download_top_stocks_by_volume():\n","    # Download S&P 500 ticker symbols\n","    snp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n","    data = pd.read_html(snp500_url)\n","    sp500_tickers = data[0]['Symbol'].tolist()\n","\n","    # Create an empty dictionary to store ticker symbols and their volumes\n","    volumes = {}\n","\n","    # Defining Start & End Date\n","    start_date = \"2010-01-01\"\n","    end_date = \"2021-01-01\"\n","\n","    # Iterate through each ticker symbol and get its historical data\n","    for ticker in sp500_tickers:\n","        try:\n","            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n","            volumes[ticker] = data['Volume'].mean()  # Use mean volume for simplicity\n","        except Exception as e:\n","            print(f\"Error downloading data for {ticker}: {e}\")\n","\n","    # Sort the dictionary by volume in descending order\n","    sorted_volumes = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n","\n","    # Take the top 100 stocks\n","    top_100_tickers = [ticker[0] for ticker in sorted_volumes[:100]]\n","\n","    # Download historical data for the top 100 stocks\n","    for ticker in top_100_tickers:\n","        try:\n","            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n","            data.to_csv(f\"./SnP_100/{ticker}.csv\")\n","            # Do something with the data, e.g., save it to a file or process it further\n","            print(f\"Downloaded data for {ticker}\")\n","        except Exception as e:\n","            print(f\"Error downloading data for {ticker}: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["download_top_stocks_by_volume()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","1 Failed download:\n","['BRK.B']: Exception('%ticker%: No timezone found, symbol may be delisted')\n","\n","1 Failed download:\n","['BF.B']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2010-01-01 -> 2021-01-01)')\n","\n","1 Failed download:\n","['CEG']: Exception(\"%ticker%: Data doesn't exist for startDate = 1262322000, endDate = 1609477200\")\n","\n","1 Failed download:\n","['GEHC']: Exception(\"%ticker%: Data doesn't exist for startDate = 1262322000, endDate = 1609477200\")\n","\n","1 Failed download:\n","['KVUE']: Exception(\"%ticker%: Data doesn't exist for startDate = 1262322000, endDate = 1609477200\")\n","\n","1 Failed download:\n","['VLTO']: Exception(\"%ticker%: Data doesn't exist for startDate = 1262322000, endDate = 1609477200\")\n"]}],"source":["snp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n","data = pd.read_html(snp500_url)\n","sp500_tickers = data[0]['Symbol'].tolist()\n","\n","volumes = {}\n","\n","# Defining Start & End Date\n","start_date = \"2010-01-01\"\n","end_date = \"2021-01-01\"\n","\n","# Iterate through each ticker symbol and get its historical data\n","for ticker in sp500_tickers:\n","    try:\n","        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n","        volumes[ticker] = data['Volume'].mean()  # Use mean volume for simplicity\n","    except Exception as e:\n","        print(f\"Error downloading data for {ticker}: {e}\")\n","\n","# Sort the dictionary by volume in descending order\n","sorted_volumes = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n","\n","# Take the top 100 stocks\n","top_100_tickers = [ticker[0] for ticker in sorted_volumes[:100]]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["['AAPL',\n"," 'BAC',\n"," 'TSLA',\n"," 'AMZN',\n"," 'GOOGL',\n"," 'GOOG',\n"," 'AMD',\n"," 'T',\n"," 'ABNB',\n"," 'AAL',\n"," 'AMAT',\n"," 'MO',\n"," 'ABT',\n"," 'AIG',\n"," 'ABBV',\n"," 'BK',\n"," 'AES',\n"," 'AXP',\n"," 'BAX',\n"," 'AFL',\n"," 'BKR',\n"," 'BBWI',\n"," 'APA',\n"," 'ADM',\n"," 'AMGN',\n"," 'ADBE',\n"," 'A',\n"," 'ANET',\n"," 'APH',\n"," 'AEP',\n"," 'ACN',\n"," 'ALL',\n"," 'MMM',\n"," 'ADI',\n"," 'AKAM',\n"," 'ADSK',\n"," 'BALL',\n"," 'AMT',\n"," 'ADP',\n"," 'APTV',\n"," 'ACGL',\n"," 'ALK',\n"," 'AEE',\n"," 'AON',\n"," 'AOS',\n"," 'AMCR',\n"," 'AMP',\n"," 'APD',\n"," 'LNT',\n"," 'AME',\n"," 'ALB',\n"," 'AXON',\n"," 'AWK',\n"," 'ALGN',\n"," 'AJG',\n"," 'AVY',\n"," 'AVB',\n"," 'ALLE',\n"," 'AIZ',\n"," 'ARE',\n"," 'ATO',\n"," 'ANSS',\n"," 'AZO',\n"," 'BRK.B',\n"," 'BF.B',\n"," 'CSCO',\n"," 'C',\n"," 'CMCSA',\n"," 'KO',\n"," 'BSX',\n"," 'BMY',\n"," 'SCHW',\n"," 'COP',\n"," 'CCL',\n"," 'CVX',\n"," 'CARR',\n"," 'BA',\n"," 'CAT',\n"," 'BBY',\n"," 'CF',\n"," 'CFG',\n"," 'CAG',\n"," 'CTSH',\n"," 'BX',\n"," 'CNP',\n"," 'CL',\n"," 'COF',\n"," 'CNC',\n"," 'CDNS',\n"," 'CAH',\n"," 'BWA',\n"," 'AVGO',\n"," 'CBRE',\n"," 'CMS',\n"," 'CMA',\n"," 'CI',\n"," 'CPB',\n"," 'COR',\n"," 'KMX',\n"," 'CME']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
